{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd925347-7e3a-422a-ac82-b74784527762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "['/Users/University/Library/CloudStorage/OneDrive-Personal/Dokumenty/studia/AI/Year3/ThesisAI/thesis-project', '/Library/Frameworks/Python.framework/Versions/3.13/lib/python313.zip', '/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13', '/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/lib-dynload', '', '/Users/University/Library/venvs/thesis-project/.venv/lib/python3.13/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Adjust the path to point to the project root directory\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Confirm the path change\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd5ac427-dce0-442b-b297-c9079ef137ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file from: /Users/University/Library/CloudStorage/OneDrive-Personal/Dokumenty/studia/AI/Year3/ThesisAI/thesis-project/results/results/SVAMP_perturbed_outputs_llama3_800_900.json\n",
      "First 200 characters of file: \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qp/7_ltyls143s9dj44nbvpw9600000gp/T/ipykernel_50875/3169815143.py:15: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(content)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m     content = f.read()\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFirst 200 characters of file:\u001b[39m\u001b[33m\"\u001b[39m, content[:\u001b[32m200\u001b[39m])  \u001b[38;5;66;03m# sanity check\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/venvs/thesis-project/.venv/lib/python3.13/site-packages/pandas/io/json/_json.py:815\u001b[39m, in \u001b[36mread_json\u001b[39m\u001b[34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[39m\n\u001b[32m    813\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[32m    814\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/venvs/thesis-project/.venv/lib/python3.13/site-packages/pandas/io/json/_json.py:1025\u001b[39m, in \u001b[36mJsonReader.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1023\u001b[39m         obj = \u001b[38;5;28mself\u001b[39m._get_object_parser(\u001b[38;5;28mself\u001b[39m._combine_lines(data_lines))\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1025\u001b[39m     obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default:\n\u001b[32m   1027\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj.convert_dtypes(\n\u001b[32m   1028\u001b[39m         infer_objects=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype_backend=\u001b[38;5;28mself\u001b[39m.dtype_backend\n\u001b[32m   1029\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/venvs/thesis-project/.venv/lib/python3.13/site-packages/pandas/io/json/_json.py:1051\u001b[39m, in \u001b[36mJsonReader._get_object_parser\u001b[39m\u001b[34m(self, json)\u001b[39m\n\u001b[32m   1049\u001b[39m obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33mframe\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m     obj = \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33mseries\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1054\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/venvs/thesis-project/.venv/lib/python3.13/site-packages/pandas/io/json/_json.py:1187\u001b[39m, in \u001b[36mParser.parse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1185\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   1186\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1187\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1189\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1190\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/venvs/thesis-project/.venv/lib/python3.13/site-packages/pandas/io/json/_json.py:1403\u001b[39m, in \u001b[36mFrameParser._parse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1399\u001b[39m orient = \u001b[38;5;28mself\u001b[39m.orient\n\u001b[32m   1401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m orient == \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1402\u001b[39m     \u001b[38;5;28mself\u001b[39m.obj = DataFrame(\n\u001b[32m-> \u001b[39m\u001b[32m1403\u001b[39m         \u001b[43mujson_loads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1404\u001b[39m     )\n\u001b[32m   1405\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m orient == \u001b[33m\"\u001b[39m\u001b[33msplit\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1406\u001b[39m     decoded = {\n\u001b[32m   1407\u001b[39m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[32m   1408\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ujson_loads(json, precise_float=\u001b[38;5;28mself\u001b[39m.precise_float).items()\n\u001b[32m   1409\u001b[39m     }\n",
      "\u001b[31mValueError\u001b[39m: Expected object or value"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result_dir = r\"/Users/University/Library/CloudStorage/OneDrive-Personal/Dokumenty/studia/AI/Year3/ThesisAI/thesis-project/results/results\"\n",
    "# # warning: starts at 100 due to error in first file generation, has to be redone after the results are fixed\n",
    "# dataframes = [pd.read_json(f\"{result_dir}/SVAMP_perturbed_outputs_llama3_{i}_{i+100}.json\") for i in range(0, 900, 100)]\n",
    "# combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "# combined_df.head()\n",
    "\n",
    "json_path = f\"{result_dir}/SVAMP_perturbed_outputs_llama3_{800}_{900}.json\"\n",
    "print(f\"Reading file from: {json_path}\")\n",
    "\n",
    "with open(json_path, 'r') as f:\n",
    "    content = f.read()\n",
    "    print(\"First 200 characters of file:\", content[:200])  # sanity check\n",
    "    df = pd.read_json(content)\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26f3feaf-b034-4a8d-8568-e0bfa087f1ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input                Each pack of dvds costs 76 dollars. If there i...\n",
      "generated_answers    {'temp_0.80': ['Step 1: The original price of ...\n",
      "expected_output                                                     51\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = combined_df\n",
    "\n",
    "# print(df['generated_answers'].iloc[0].keys())\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dafa1017-297a-4fc6-aab8-2e095c517342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77fd4023-376b-483e-b2d3-3088679244ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\venvs\\thesis\\venv\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:558: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer files: {'vocab_file': 'spm.model', 'tokenizer_file': 'tokenizer.json'}\n"
     ]
    }
   ],
   "source": [
    "def compute_uncertainty_for_row(row):\n",
    "    \"\"\" Compute uncertainty for a single DataFrame row. \"\"\"\n",
    "    generated_answers = row[\"generated_answers\"]\n",
    "    # original_answer = row[\"text\"]  # Assuming the original answer is the unperturbed input\n",
    "\n",
    "    temperature_samples, trigger_samples, rephrase_samples, original_answer = prepare_samples(generated_answers)\n",
    "\n",
    "    # Instantiate the estimator\n",
    "    estimator = ProbingUncertaintyEstimator(original_answer)\n",
    "    \n",
    "    # Estimate uncertainty\n",
    "    uncertainty = estimator.estimate_uncertainty(\n",
    "        temperature_samples=temperature_samples,\n",
    "        trigger_samples=trigger_samples,\n",
    "        rephrase_samples=rephrase_samples\n",
    "    )\n",
    "\n",
    "    return uncertainty\n",
    "\n",
    "# Apply to entire DataFrame\n",
    "combined_df[\"uncertainty\"] = combined_df.apply(compute_uncertainty_for_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2580afa-3a91-44ab-921f-23e6ae9a7c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: sentencepiece\n",
      "Version: 0.2.0\n",
      "Summary: SentencePiece python wrapper\n",
      "Home-page: https://github.com/google/sentencepiece\n",
      "Author: Taku Kudo\n",
      "Author-email: taku@google.com\n",
      "License: Apache\n",
      "Location: c:\\venvs\\thesis\\venv\\lib\\site-packages\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show sentencepiece"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
